\relax 
\citation{mnistMATLAB2}
\citation{nnDiagramStack}
\citation{nnBlog}
\citation{deepBig}
\citation{mnistDATABASE}
\citation{humanPerf}
\citation{mnistMATLAB2}
\citation{mnistMATLAB2}
\citation{nnDiagramStack}
\citation{nnDiagramStack}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The MNIST database}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample numbers from MNIST \cite  {mnistMATLAB2}.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:mathworksmnistneuralnetfinal}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Artificial neural network}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visualization of a neural network with one hidden layer\cite  {nnDiagramStack}. \relax }}{3}}
\newlabel{fig:nndiagram}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Neural Network Walkthrough}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Parameter Initialization}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Forward Propagation}{3}}
\citation{nnBlog}
\citation{nnBlog}
\citation{nnBlog}
\newlabel{eqn:forProp}{{1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Compute loss}{4}}
\newlabel{eqn:loss}{{2}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}Backward propagation}{4}}
\newlabel{eqn:outputBack}{{3}{4}}
\newlabel{eqn:allOtherBack}{{4}{4}}
\newlabel{eqn:updateWeight}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Gradient Decent}{4}}
\newlabel{eqn:gdes}{{6}{4}}
\citation{deepBig}
\citation{deepBig}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A visualization of forward and backward propagation \cite  {nnBlog}.\relax }}{5}}
\newlabel{fig:forwardbackwardprop}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Activation Function}{5}}
\newlabel{eqn:tanH}{{7}{5}}
\newlabel{eqn:dtanh}{{8}{5}}
\newlabel{eqn:sig}{{9}{5}}
\newlabel{eqn:dsig}{{10}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Pitfalls}{5}}
\citation{Hicken18gradProjDes}
\citation{Hicken18gradProjRubric}
\citation{usingMNIST}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of sigmoid and Tanh function\relax }}{6}}
\newlabel{fig:sigvstanh}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Run times for various neural network architectures\cite  {deepBig}.\relax }}{6}}
\newlabel{fig:nnruntime}{{5}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Implementation}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Object Oriented Programming in MATLAB}{6}}
\citation{matlabNNBeg}
\newlabel{fig:250results}{{6a}{7}}
\newlabel{sub@fig:250results}{{a}{7}}
\newlabel{fig:250resultslog}{{6b}{7}}
\newlabel{sub@fig:250resultslog}{{b}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The results from the simple network for the first 1000 epochs.\relax }}{7}}
\newlabel{fig:250_all}{{6}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MATLAB Code}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Simple Neural Net}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Comparison of different hidden layer sizes}{7}}
\citation{len5}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Net accuracy for different layer sizes.\relax }}{8}}
\newlabel{fig:multiplelayers}{{7}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Multiple hidden layers}{8}}
\newlabel{fig:250results_l2}{{8a}{8}}
\newlabel{sub@fig:250results_l2}{{a}{8}}
\newlabel{fig:250resultslog_l2}{{8b}{8}}
\newlabel{sub@fig:250resultslog_l2}{{b}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The results from the two layer network for the first 2000 epochs.\relax }}{8}}
\newlabel{fig:250_all_l2}{{8}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{8}}
\bibstyle{unsrt}
\bibdata{ref}
\bibcite{mnistMATLAB2}{1}
\bibcite{nnDiagramStack}{2}
\bibcite{nnBlog}{3}
\bibcite{deepBig}{4}
\bibcite{mnistDATABASE}{5}
\bibcite{humanPerf}{6}
\bibcite{Hicken18gradProjDes}{7}
\bibcite{Hicken18gradProjRubric}{8}
\bibcite{usingMNIST}{9}
\bibcite{matlabNNBeg}{10}
\bibcite{len5}{11}
\@writefile{toc}{\contentsline {section}{Appendix}{9}}
\@writefile{lol}{\contentsline {lstlisting}{C:/Users/Philip/Documents/GitHub/DesignOpt/designOpNN/latexCode/NN\textunderscore Master.m}{9}}
\@writefile{lol}{\contentsline {lstlisting}{C:/Users/Philip/Documents/GitHub/DesignOpt/designOpNN/latexCode/philipNeuralNet.m}{12}}
\@writefile{lol}{\contentsline {lstlisting}{C:/Users/Philip/Documents/GitHub/DesignOpt/designOpNN/latexCode/testAcc.m}{14}}
\@writefile{lol}{\contentsline {lstlisting}{C:/Users/Philip/Documents/GitHub/DesignOpt/designOpNN/latexCode/plotAcc.m}{15}}
\newlabel{LastPage}{{}{15}}
\xdef\lastpage@lastpage{15}
\gdef\lastpage@lastpageHy{}
